{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T10:12:32.218295Z",
     "start_time": "2024-06-22T10:12:32.140040Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import bz2file as bz2\n",
    "import os\n",
    "from typing import Tuple, Optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to the Gisette Dataset\n",
    "\n",
    "The Gisette dataset is a well-known benchmark dataset in the field of machine learning, particularly used for feature selection and binary classification tasks. It was originally part of the NIPS 2003 feature selection challenge. The dataset consists of handwritten digit images, where the task is to distinguish between the digits '4' and '9'.\n",
    "\n",
    "## Dataset Characteristics\n",
    "\n",
    "- **Features:** The dataset contains 5000 features, many of which are redundant or irrelevant, making it a good test for feature selection algorithms.\n",
    "- **Instances:** There are 7000 instances in the training set and 1000 instances in the test set.\n",
    "- **Classes:** The labels are binary, with two classes representing the digits '4' and '9'.\n",
    "\n",
    "## Usage\n",
    "\n",
    "The Gisette dataset is often used to evaluate the performance of various machine learning algorithms, especially those designed for high-dimensional data. It provides a challenging testbed for algorithms due to its high dimensionality and the presence of irrelevant features.\n",
    "\n",
    "## References\n",
    "\n",
    "put a reference here\n",
    "\n",
    "All features are scaled.\n",
    "\n",
    "The Gisette dataset is often used to evaluate the performance of various machine learning algorithms, especially those designed for high-dimensional data. It provides a challenging testbed for algorithms due to its high dimensionality and the presence of irrelevant features.\n",
    "each line is like this: \n",
    "-1 1:-1 2:-1 3:0.913914 4:-1 5:-1 6:0.4530 ...\n",
    "the first number is either 1 or -1 (label y)\n",
    " and it is followed by 5000 pairs of the form integer_index. the floats are the x values\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76d2d9a077d300a3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.utils import read_gisette_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T10:12:32.913437Z",
     "start_time": "2024-06-22T10:12:32.756398Z"
    }
   },
   "id": "e40611c5cf56a43f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_LINES = 4500\n",
    "file_path_train = os.path.join(\"..\",\"data\",\"gisette_scale.bz2\")\n",
    "file_path_test = os.path.join(\"..\",\"data\",\"gisette_scale.t.bz2\")\n",
    "\n",
    "\n",
    "y_train, X_train = read_gisette_data(file_path_train, max_lines=MAX_LINES)\n",
    "y_test, X_test = read_gisette_data(file_path_test, max_lines=MAX_LINES)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T10:12:42.938153Z",
     "start_time": "2024-06-22T10:12:33.318744Z"
    }
   },
   "id": "1325be0581428573",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM problem definition\n",
    "\n",
    "* the optimization problem we should solve it the following one:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\min \\quad \\frac{1}{2} \\|\\mathbf{w}\\|^2 + C \\sum_{i=1}^m \\xi_i \\\\\n",
    "& \\text{subject to} \\quad y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0, \\quad i = 1, \\dots, m\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "According to Platt's algorithm [put reference here] it is preferrable to solve the dual, which is the following:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\max_{\\boldsymbol{\\alpha}} \\quad \\sum_{i=1}^n \\alpha_i - \\frac{1}{2} \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j \\mathbf{x}_i \\cdot \\mathbf{x}_j \\\\\n",
    "& \\text{subject to} \\sum_{i=1}^n \\alpha_i y_i = 0 \\\\\n",
    "& \\quad \\quad \\quad \\quad 0 \\leq \\alpha_i \\leq C, \\quad i = 1, \\dots, m\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "     "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73c5ce1ebe99c954"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(C=0.1, kernel='linear')",
      "text/html": "<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm = SVC(kernel='linear', C=0.1)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:47:58.826153Z",
     "start_time": "2024-06-22T15:47:50.383672Z"
    }
   },
   "id": "1fbaf86b4fe3cc56",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on test set: 0.9670\n",
      "F1 of SVM on test set: 0.9669\n",
      "Precision of SVM on test set: 0.9698\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of SVM on test set: {accuracy:.4f}')\n",
    "print(f'F1 of SVM on test set: {f1:.4f}')\n",
    "print(f'Precision of SVM on test set: {precision:.4f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:48:00.219218Z",
     "start_time": "2024-06-22T15:47:58.827099Z"
    }
   },
   "id": "90fe29e00b80b4bf",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom SMO algorithm\n",
    "\n",
    "* Create the SMO algorith\n",
    "* use classes in scikit-learn similar manner, so that has fit and predict methods for training and inference\n",
    "* the cor of the classifier class are the two functions described in Platt's paper `take_step` and `examine_example`\n",
    "* The main routine has been replaced with `fit` and has the two "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9c7c80000d493dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SVM_classifier:\n",
    "    def __init__(self, X, y, kernel:str ='linear', C:float =1, epsilon:float = 1e-8, tol:float = 0.001, max_iter:int= 500):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.kernel = kernel\n",
    "        self.kernel_func = self.select_kernel(self.kernel)\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon # error margin \n",
    "        self.tol = tol # tolerance for KKT\n",
    "        self.max_iter = max_iter\n",
    "        self.m, self.n = np.shape(self.X) # m is number of samples, n number of features\n",
    "        \n",
    "        self.alphas = np.zeros(self.m)\n",
    "        self.Error_cache = np.zeros(self.m) #- y \n",
    "        \n",
    "        # If the kernel is linear we can store a single weight vector and use the alternative implemented in SVM\n",
    "        \n",
    "        self.w = np.zeros(self.n)\n",
    "        self.b = 0 # intercept            \n",
    "        \n",
    "        \n",
    "    def select_kernel(self, kernel:str):\n",
    "        \n",
    "        ''' We have to choose a kernel based on the kernel type argument\n",
    "        here we can use only linear or the gaussion, no other kernels are available'''\n",
    "        \n",
    "        if kernel == 'linear':\n",
    "            return self.linear_kernel\n",
    "        elif kernel == 'rbf':\n",
    "            return self.rbf_kernel\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported kernel type: {kernel}\")\n",
    "    \n",
    "    def linear_kernel(self, x1: np.ndarray, x2: np.ndarray) -> np.ndarray:\n",
    "        return x1 @ x2.T\n",
    "    \n",
    "    def rbf_kernel(self, x1, x2):\n",
    "\n",
    "        \"\"\"\n",
    "        RBF kernel implementation, i.e. K(u,v) = exp(-gamma_rbf*|u-v|^2).\n",
    "        gamma_rbf is a hyper-parameter of the model.\n",
    "\n",
    "        \"\"\"\n",
    "        # we use the default parameter gamma=1\n",
    "        gamma = 1\n",
    "        \n",
    "        # In case u, v are vectors, convert to row vector\n",
    "        if np.ndim(x1) == 1:\n",
    "            x1 = x1[np.newaxis, :]\n",
    "\n",
    "        if np.ndim(x2) == 1:\n",
    "            x2 = x2[np.newaxis, :]\n",
    "\n",
    "        dist_squared = np.linalg.norm(x1[:, :, np.newaxis] - x2.T[np.newaxis, :, :], axis=1) ** 2\n",
    "        dist_squared = np.squeeze(dist_squared)\n",
    "\n",
    "        return np.exp(-gamma * dist_squared)\n",
    "    \n",
    "    \n",
    "    def predict(self,x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\" Predicts the labels for the instance\n",
    "            and the respective score.\"\"\"\n",
    "\n",
    "        if self.kernel != 'linear':\n",
    "            scores = (self.alphas * self.y) @ self.kernel_func(self.X,x) - self.b\n",
    "            \n",
    "        else:\n",
    "            scores = self.w @ x.T - self.b\n",
    "        \n",
    "        pred = np.sign(scores)\n",
    "\n",
    "        return pred, scores\n",
    "    \n",
    "    def get_error(self, i: int) -> float:\n",
    "        \"\"\"\n",
    "        Computes the error for each instance\n",
    "        :param i: i-th instance\n",
    "        :return: the difference between scores\n",
    "        \"\"\"\n",
    "        return self.predict(self.X[i,:])[1] - self.y[i]\n",
    "    \n",
    "    def get_params(self) -> dict:\n",
    "        \"\"\"\n",
    "        Returns the parameter dictionary for model parameters \n",
    "        \n",
    "        \"\"\"\n",
    "        if self.kernel != 'linear':\n",
    "            self.w = ((self.alphas * self.y) @ self.X)\n",
    "        return {'w':self.w, 'b':self.b}\n",
    "    \n",
    "    def take_step(self, i1:int=None, i2:int=None) -> int:\n",
    "        \"\"\"\n",
    "        takes one step of the SMO algorithm\n",
    "        :param i1: i1-th training instance \n",
    "        :param i2: i2-th training instance\n",
    "        :return: 1 if success else 0\n",
    "        \"\"\"\n",
    "        #print(\"I an in take_step.\")\n",
    "        if i1==i2:\n",
    "            #print(\"i1==i2\\n0 returned.\")\n",
    "            return 0\n",
    "        \n",
    "        # Set all required parameters\n",
    "        a1 = self.alphas[i1]\n",
    "        a2 = self.alphas[i2]\n",
    "        \n",
    "        x1 = self.X[i1,:]\n",
    "        x2 = self.X[i2,:]\n",
    "        \n",
    "        y1 = self.y[i1]\n",
    "        y2 = self.y[i2]\n",
    "        \n",
    "        E1 = self.get_error(i1)\n",
    "        E2 = self.get_error(i2)\n",
    "        \n",
    "        # Define parameter s\n",
    "        s = y1*y2\n",
    "        \n",
    "        # Compute L, H via equations (13) and (14) from Platt\n",
    "        if y1!=y2:\n",
    "            L = max(0,a2-a1)\n",
    "            H = min(self.C,self.C+a2-a1)\n",
    "        else:\n",
    "            L = max(0,a2+a1-self.C)\n",
    "            H = min(self.C,a2+a1)\n",
    "            \n",
    "        if L==H:\n",
    "            #print(\"L==H\\n0 returned.\")\n",
    "            return 0\n",
    "        \n",
    "        k11 = self.kernel_func(x1,x1)\n",
    "        k22 = self.kernel_func(x2,x2)\n",
    "        k12 = self.kernel_func(x1,x2)\n",
    "        \n",
    "        # Compute the second derivative of the objective function along the diagonal line\n",
    "        eta = k11 + k22 - 2.0*k12\n",
    "        \n",
    "        if eta > 0:\n",
    "            # Normal circumstances, using Equations (16)-(18) to compute a1 and a2\n",
    "            a2_new = a2 +y2*(E1-E2)/eta\n",
    "            \n",
    "            if a2_new>=H:\n",
    "                a2_new = H\n",
    "            if a2_new<=L:\n",
    "                a2_new = L\n",
    "        else:\n",
    "            # Strange case, we use Equations (19)\n",
    "            f1 = y1*(E1 + self.b) - a1*k11 - s*a2*k12\n",
    "            f2 = y2*(E2 + self.b) - s*a1*k12 - a2*k22\n",
    "            L1 = a1 + s*(a2 - L)\n",
    "            H1 = a1 + s*(a2 - H)\n",
    "            psi_L = L1*f1 + L*f2 + 0.5*L1*L1*k11 + 0.5*L*L*k22 + s*L*L1*k12\n",
    "            psi_H = H1*f1 + H*f2 + 0.5*H1*H1*k11 + 0.5*H*H*k22 + s*H*H1*k12\n",
    "            \n",
    "            if psi_L < (psi_H - self.epsilon):\n",
    "                a2_new = L\n",
    "            elif psi_L > (psi_H + self.epsilon):\n",
    "                a2_new = H\n",
    "            else:\n",
    "                a2_new = a2\n",
    "\n",
    "        if a2 < self.epsilon:\n",
    "           a2 = 0.0\n",
    "        elif a2 > self.C - self.epsilon:\n",
    "           a2 = self.C\n",
    "        \n",
    "        if np.abs(a2_new - a2) < (self.epsilon * (a2_new + a2 + self.epsilon)):\n",
    "            #print(\"off numerical tolerance\\n0 returned.\")\n",
    "            return 0\n",
    "        \n",
    "        # Calculate a1_new\n",
    "        a1_new = a1 + s*(a2 - a2_new)\n",
    "        \n",
    "        # Push alphas to boundaries\n",
    "        if a1_new < self.epsilon:\n",
    "            a1_new = 0\n",
    "        if a1_new > (self.C - self.epsilon):\n",
    "            a1_new = self.C\n",
    "        \n",
    "        # Update threshold b\n",
    "        b1 = self.b + E1 + y1*(a1_new - a1)*k11 + y2*(a2_new - a2)*k12\n",
    "        b2 = self.b + E2 + y1*(a1_new - a1)*k12 + y2*(a2_new - a2)*k22\n",
    "        \n",
    "        if 0 < a1_new < self.C:\n",
    "            b_new = b1\n",
    "        elif 0 < a2_new < self.C:\n",
    "            b_new = b2\n",
    "        else:\n",
    "            b_new = 0.5*(b1 + b2)\n",
    "            \n",
    "        # Update weight's vector if Linear kernel\n",
    "        if self.kernel == 'linear':\n",
    "            self.w = self.w + y1*(a1_new - a1)*x1 + y2*(a2_new - a2)*x2\n",
    "            \n",
    "        # Update Error_cache using alphas (see reference)\n",
    "        \n",
    "        # if a1 & a2 are not at bounds, the error will be 0\n",
    "        self.Error_cache[i1] = 0\n",
    "        self.Error_cache[i2] = 0\n",
    "        \n",
    "        # Update error for non boundary elements\n",
    "        inner_indices = [idx for idx, a in enumerate(self.alphas) if 0 < a < self.C]\n",
    "        for i in inner_indices:\n",
    "            self.Error_cache[i] += \\\n",
    "                 y1*(a1_new - a1)*self.kernel_func(x1, self.X[i,:]) \\\n",
    "               + y2*(a2_new - a2)*self.kernel_func(x2, self.X[i,:]) \\\n",
    "               + (self.b - b_new)\n",
    "        \n",
    "        \n",
    "        # Update alphas\n",
    "        self.alphas[i1] = a1_new\n",
    "        self.alphas[i2] = a2_new\n",
    "        \n",
    "        # Update b\n",
    "        self.b = b_new\n",
    "        \n",
    "        #print(\"successfull pass\")\n",
    "        return 1 # sucessfull pass\n",
    "    \n",
    "    def examine_example(self, i2:int=None):\n",
    "        \"\"\"\n",
    "        Examine the i2-th example in the algorithm to determine\n",
    "        if eligible for usage in optimization pair\n",
    "        :param i2: example to examine\n",
    "        :return: 1 if successful, 0 if not\n",
    "        \"\"\"\n",
    "        \n",
    "        y2 = self.y[i2]\n",
    "        a2 = self.alphas[i2]\n",
    "        E2 = self.get_error(i2)\n",
    "        r2 = E2 * y2\n",
    "        #print(\"I am in examine_example()\")\n",
    "        # Check if error is within tolerance\n",
    "        if (r2 < -self.tol and a2 < self.C) or (r2 > self.tol and a2 > 0):\n",
    "            #print(\"Error within tolerance.\")\n",
    "            # If there are more than one non-bound elements use the second heuristic \n",
    "            if np.count_nonzero((0 < self.alphas) & (self.alphas < self.C)) > 1:\n",
    "                \n",
    "                # use section 2.2 to select i1\n",
    "                if E2 > 0:\n",
    "                    i1 = np.argmin(self.Error_cache)\n",
    "                else:\n",
    "                    i1 = np.argmax(self.Error_cache)\n",
    "\n",
    "                if self.take_step(i1, i2):\n",
    "                    return 1\n",
    "                \n",
    "            # Loop over all non-zero and non-C alpha, starting at a random point\n",
    "\n",
    "            # Get indices where 0 < alpha < self.C\n",
    "            i1_array = np.where((0 < self.alphas) & (self.alphas < self.C))[0]\n",
    "\n",
    "            # Roll the array by a random number of positions to ensure that we will pass all\n",
    "            random_shift = np.random.choice(np.arange(self.m))\n",
    "            i1_list = np.roll(i1_array, random_shift)\n",
    "            \n",
    "            # Loop over all non-boundary elements\n",
    "            for i1 in i1_list:\n",
    "                if self.take_step(i1, i2):\n",
    "                    return 1\n",
    "\n",
    "            # Loop over all possible alpha elements, starting at a random point\n",
    "            i1_list = np.roll(np.arange(self.m), np.random.choice(np.arange(self.m)))\n",
    "            for i1 in i1_list:\n",
    "                if self.take_step(i1, i2):\n",
    "                    return 1\n",
    "                \n",
    "                    \n",
    "        return 0\n",
    "    \n",
    "    def fit(self) -> None:\n",
    "        \"\"\"This is the equivalent of the main routine in the original SMO paper.\n",
    "            We use it for training the algorithm.\"\"\"\n",
    "        iteration_number = 0 # We count the number of iterations and bounded below max_iter\n",
    "        numbers_changed = 0\n",
    "        examine_all = True\n",
    "    \n",
    "        while numbers_changed > 0 or examine_all:\n",
    "            \n",
    "            if iteration_number >= self.max_iter:\n",
    "                break\n",
    "                \n",
    "            numbers_changed = 0\n",
    "            if examine_all:\n",
    "                # Loop over all training examples\n",
    "                for i in range(self.m):\n",
    "                    numbers_changed += self.examine_example(i)\n",
    "            \n",
    "            else: \n",
    "                # Loop i over examples where alpha is not 0 & not C\n",
    "                i_array = np.where((0 < self.alphas) & (self.alphas < self.C))[0]\n",
    "                for i in i_array:\n",
    "                    numbers_changed += self.examine_example(i)\n",
    "                    \n",
    "            if examine_all:\n",
    "                examine_all = False\n",
    "            if numbers_changed == 0:\n",
    "                examine_all = True\n",
    "                \n",
    "            iteration_number += 1\n",
    "            \n",
    "        print(f\"Training process completed.\")\n",
    "            #return self.b, self.w\n",
    "        \n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:00:00.896973Z",
     "start_time": "2024-06-22T15:00:00.876313Z"
    }
   },
   "id": "fceae32f557ce1c1",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = SVM_classifier(X_train, y_train, kernel='linear', C=1)\n",
    "model.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T10:37:34.631716Z",
     "start_time": "2024-06-22T10:31:44.424260Z"
    }
   },
   "id": "c14d232879fe68b1",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on test set: 0.9670\n",
      "F1 of SVM on test set: 0.9669\n",
      "Precision of SVM on test set: 0.9698\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred, scores = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of SVM on test set: {accuracy:.4f}')\n",
    "print(f'F1 of SVM on test set: {f1:.4f}')\n",
    "print(f'Precision of SVM on test set: {precision:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T10:37:34.652174Z",
     "start_time": "2024-06-22T10:37:34.632854Z"
    }
   },
   "id": "33c1b9d9c4b63256",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e561a1128874ba6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple hyperparameter tuner for C"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54c5ce1b96928b0e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def tune_hyperparameter_C(X, y, kernel='linear', metric='accuracy', C_range=[0.1, 1, 10, 100], cv=5):\n",
    "    \"\"\"\n",
    "    Tunes the hyperparameter C for the SVM_classifier using cross-validation based on the selected metric.\n",
    "\n",
    "    Parameters:\n",
    "    X (array-like): Feature matrix.\n",
    "    y (array-like): Target labels.\n",
    "    kernel (str): The kernel type ('linear' or 'rbf').\n",
    "    metric (str): The metric to optimize during hyperparameter tuning ('accuracy', 'precision', 'recall', 'f1').\n",
    "    C_range (list): List of C values to try during cross-validation.\n",
    "    cv (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "    float: Best value of C found during hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    best_C = None\n",
    "    best_score = -np.inf if metric in ['precision', 'recall', 'f1'] else np.inf\n",
    "    \n",
    "    for C in C_range:\n",
    "        scores = []\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            \n",
    "            clf = SVM_classifier(X_train, y_train, kernel=kernel, C=C)\n",
    "            clf.fit()\n",
    "            \n",
    "            y_pred, _ = clf.predict(X_val)\n",
    "            score = calculate_score(y_val, y_pred, metric)\n",
    "            scores.append(score)\n",
    "        \n",
    "        mean_score = np.mean(scores)\n",
    "        \n",
    "        if (metric in ['precision', 'recall', 'f1'] and mean_score > best_score) or \\\n",
    "           (metric == 'accuracy' and mean_score < best_score):\n",
    "            best_score = mean_score\n",
    "            best_C = C\n",
    "    \n",
    "    return best_C\n",
    "\n",
    "def calculate_score(y_true, y_pred, metric):\n",
    "    \"\"\"\n",
    "    Calculates the score based on the specified metric.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): True labels.\n",
    "    y_pred (array-like): Predicted labels.\n",
    "    metric (str): The metric to calculate ('accuracy', 'precision', 'recall', 'f1').\n",
    "\n",
    "    Returns:\n",
    "    float: Score based on the metric.\n",
    "    \"\"\"\n",
    "    if metric == 'accuracy':\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    elif metric == 'precision':\n",
    "        return precision_score(y_true, y_pred)\n",
    "    elif metric == 'recall':\n",
    "        return recall_score(y_true, y_pred)\n",
    "    elif metric == 'f1':\n",
    "        return f1_score(y_true, y_pred)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported metric: {metric}. Please choose from 'accuracy', 'precision', 'recall', 'f1'.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:00:13.056490Z",
     "start_time": "2024-06-22T15:00:13.048233Z"
    }
   },
   "id": "5a545cf00a2f0199",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "Training process completed.\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "results = tune_hyperparameter_C(X_train, y_train, metric='accuracy', C_range=[0.1, 1, 10, 100],cv=3)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:36:00.194671Z",
     "start_time": "2024-06-22T15:00:31.121055Z"
    }
   },
   "id": "afb1c4c8a4b666e4",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process completed.\n",
      "Accuracy of SVM on test set: 0.9670\n",
      "F1 of SVM on test set: 0.9669\n",
      "Precision of SVM on test set: 0.9698\n"
     ]
    }
   ],
   "source": [
    "model = SVM_classifier(X_train, y_train, kernel='linear', C=0.1)\n",
    "model.fit()\n",
    "# Predict on the test data\n",
    "y_pred, scores = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of SVM on test set: {accuracy:.4f}')\n",
    "print(f'F1 of SVM on test set: {f1:.4f}')\n",
    "print(f'Precision of SVM on test set: {precision:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:46:10.985304Z",
     "start_time": "2024-06-22T15:40:30.465677Z"
    }
   },
   "id": "73b66d55632b9e4",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95cf2e4916dc21d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
